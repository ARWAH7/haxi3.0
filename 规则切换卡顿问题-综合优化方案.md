# 规则切换卡顿问题 - 综合优化方案

## 📋 问题概述

### 用户反馈
各规则之间切换数据加载有卡顿，影响用户体验。

### 8个采样规则
```
3秒   (步长 1)   → 需要 264 条符合规则的数据
6秒   (步长 2)   → 需要 264 条符合规则的数据
9秒   (步长 3)   → 需要 264 条符合规则的数据
15秒  (步长 5)   → 需要 264 条符合规则的数据
30秒  (步长 10)  → 需要 264 条符合规则的数据
1分钟 (步长 20)  → 需要 264 条符合规则的数据
3分钟 (步长 60)  → 需要 264 条符合规则的数据
5分钟 (步长 100) → 需要 264 条符合规则的数据
```

### 核心问题分析

| 问题 | 描述 | 影响 | 优先级 |
|------|------|------|--------|
| 问题1 | 每次切换规则都强制重新加载数据 | 用户体验差，每次切换延迟~500ms | 高 |
| 问题2 | 后端每次都加载30,000条原始数据 | 资源浪费，性能低下 | 高 |
| 问题3 | 前端没有缓存机制 | 无法复用已加载的数据 | 高 |
| 问题4 | loadHistoryBlocks依赖项过多 | 不必要的函数重新创建 | 中 |

---

## 🎯 综合优化方案

### 核心思路

**前端缓存 + 后端动态加载 = 最优性能**

```
┌─────────────────────────────────────────────────────────────┐
│                        用户切换规则                          │
└─────────────────────────────────────────────────────────────┘
                              ↓
                    ┌─────────────────┐
                    │  检查前端缓存    │
                    └─────────────────┘
                              ↓
                    ┌─────────────────┐
                    │  缓存命中？      │
                    └─────────────────┘
                      ↙           ↘
                   是                否
                    ↓                 ↓
          ┌──────────────┐    ┌──────────────────┐
          │ 使用缓存数据  │    │ 后端动态加载数据  │
          │   ~10ms      │    │   ~35-110ms      │
          └──────────────┘    └──────────────────┘
                    ↓                 ↓
                    └────────┬────────┘
                             ↓
                    ┌─────────────────┐
                    │  更新缓存        │
                    └─────────────────┘
                             ↓
                    ┌─────────────────┐
                    │  显示数据        │
                    └─────────────────┘
```

---

## 🔧 方案详解

### 方案1：前端缓存机制（问题1 + 问题3）

#### 核心设计

**缓存数据结构**：
```typescript
const [blocksCache, setBlocksCache] = useState<Map<string, BlockData[]>>(new Map());

// 缓存示例
blocksCache = {
  "1-0":   [264条符合步长1的最新数据],   // 3秒规则
  "2-0":   [264条符合步长2的最新数据],   // 6秒规则
  "3-0":   [264条符合步长3的最新数据],   // 9秒规则
  "5-0":   [264条符合步长5的最新数据],   // 15秒规则
  "10-0":  [264条符合步长10的最新数据],  // 30秒规则
  "20-0":  [264条符合步长20的最新数据],  // 1分钟规则
  "60-0":  [264条符合步长60的最新数据],  // 3分钟规则
  "100-0": [264条符合步长100的最新数据], // 5分钟规则
}
```

**缓存规则**：
1. ✅ **只缓存符合规则的数据**：不符合步长的区块不保存
2. ✅ **固定264条**：每个规则缓存固定264条符合规则的最新数据
3. ✅ **自动更新**：新数据到达时，删除最旧的数据
4. ✅ **实时同步**：WebSocket更新时同步缓存
5. ✅ **及时清理**：缓存大小限制为10个规则，超过时自动删除最旧的缓存

**内存管理策略**：
```typescript
// 缓存大小限制
const MAX_CACHE_SIZE = 10;  // 最多缓存10个规则

// 单个规则内存占用：264条 × 0.5KB = 132KB
// 10个规则总内存占用：10 × 132KB = 1.32MB（可接受）

// 及时清理策略：FIFO（先进先出）
if (newCache.size > MAX_CACHE_SIZE) {
  const firstKey = newCache.keys().next().value;
  newCache.delete(firstKey);
  console.log(`[缓存] 🗑️ 删除最旧的缓存: ${firstKey}`);
}
```

#### 实现代码

```typescript
// 1. 添加缓存状态
const [blocksCache, setBlocksCache] = useState<Map<string, BlockData[]>>(new Map());

// 2. 修改 loadHistoryBlocks 函数
const loadHistoryBlocks = useCallback(async (forceReload: boolean = false) => {
  try {
    const ruleValue = activeRule?.value || 1;
    const startBlock = activeRule?.startBlock || 0;
    const requiredFiltered = 264;  // 固定需要264条
    const cacheKey = `${ruleValue}-${startBlock}`;
    
    // ✅ 优先使用缓存数据
    if (!forceReload && blocksCache.has(cacheKey)) {
      const cachedData = blocksCache.get(cacheKey)!;
      if (cachedData.length >= requiredFiltered * 0.9) {
        console.log(`[缓存] ✅ 使用缓存数据: ${cachedData.length} 条 (规则: ${activeRule?.label})`);
        setAllBlocks(cachedData);
        setIsLoading(false);
        return;  // 🚀 缓存命中，直接返回，不进行网络请求
      }
    }
    
    // ✅ 缓存未命中，从后端加载
    setIsLoading(true);
    
    const BACKEND_API_URL = 'http://localhost:3001';
    const response = await fetch(
      `${BACKEND_API_URL}/api/blocks?limit=${requiredFiltered}&ruleValue=${ruleValue}&startBlock=${startBlock}`
    );
    const result = await response.json();
    
    if (result.success) {
      setAllBlocks(result.data);
      
      // ✅ 更新缓存
      setBlocksCache(prev => {
        const newCache = new Map(prev);
        newCache.set(cacheKey, result.data);
        
        // ✅ 及时清理：限制缓存大小（最多保留 10 个规则）
        if (newCache.size > 10) {
          const firstKey = newCache.keys().next().value;
          newCache.delete(firstKey);
          console.log(`[缓存] 🗑️ 删除最旧的缓存: ${firstKey}`);
          console.log(`[缓存] 📊 当前缓存: ${newCache.size} 个规则`);
        }
        
        return newCache;
      });
      
      console.log(`[API] ✅ 后端加载完成: ${result.data.length} 条`);
      console.log(`[缓存] 💾 已缓存规则: ${cacheKey}`);
    }
    
    setIsLoading(false);
  } catch (error) {
    console.error('[API] 加载失败:', error);
    setIsLoading(false);
  }
}, [activeRule, blocksCache]);

// 3. 修改规则切换逻辑
useEffect(() => {
  if (!wsConnected || !activeRule) return;
  
  // ✅ 立即切换，不使用防抖（因为有缓存，切换很快）
  console.log(`[规则变化] 切换到规则: ${activeRule.label}`);
  loadHistoryBlocks(false);  // ✅ 不强制重新加载，优先使用缓存
}, [activeRuleId, wsConnected, loadHistoryBlocks]);

// 4. WebSocket 数据更新时同步缓存
setAllBlocks(prev => {
  // ... 数据更新逻辑 ...
  
  // ✅ 同步更新缓存
  if (currentRule) {
    const cacheKey = `${currentRule.value}-${currentRule.startBlock}`;
    setBlocksCache(prevCache => {
      const newCache = new Map(prevCache);
      newCache.set(cacheKey, updated);  // 缓存符合规则的264条最新数据
      return newCache;
    });
  }
  
  return updated;
});
```

---

### 方案2：后端动态加载（问题2）

#### 核心设计

**动态计算公式**：
```
需要加载的原始数据量 = 需要的过滤后数据量 × 步长 × 安全系数
```

**参数说明**：
- 需要的过滤后数据量：264条
- 步长：ruleValue（1, 2, 3, 5, 10, 20, 60, 100）
- 安全系数：1.5

**计算结果**：
| 规则 | 步长 | 计算公式 | 加载量 | 优化效果 |
|------|------|---------|--------|---------|
| 3秒 | 1 | 264 × 1 × 1.5 | 396 条 | 98.7% ↓ |
| 6秒 | 2 | 264 × 2 × 1.5 | 792 条 | 97.4% ↓ |
| 9秒 | 3 | 264 × 3 × 1.5 | 1,188 条 | 96.0% ↓ |
| 15秒 | 5 | 264 × 5 × 1.5 | 1,980 条 | 93.4% ↓ |
| 30秒 | 10 | 264 × 10 × 1.5 | 3,960 条 | 86.8% ↓ |
| 1分钟 | 20 | 264 × 20 × 1.5 | 7,920 条 | 73.6% ↓ |
| 3分钟 | 60 | 264 × 60 × 1.5 | 23,760 条 | 20.8% ↓ |
| 5分钟 | 100 | 264 × 100 × 1.5 | 30,000 条 | 0% |

#### 实现代码

```typescript
// backend/src/api.ts

app.get('/api/blocks', async (req, res) => {
  try {
    const limit = parseInt(req.query.limit as string) || 264;
    const ruleValue = parseInt(req.query.ruleValue as string) || 1;
    const startBlock = parseInt(req.query.startBlock as string) || 0;
    
    // ✅ 动态计算需要加载的原始数据量
    const safetyFactor = 1.5;
    const estimatedRawBlocks = Math.ceil(limit * ruleValue * safetyFactor);
    const MAX_RAW_BLOCKS = Math.min(estimatedRawBlocks, 30000);
    
    console.log(`[API] 📥 规则过滤请求: 步长 ${ruleValue}, 需要 ${limit} 条`);
    console.log(`[API] 📊 预估加载: ${estimatedRawBlocks} 条，实际加载: ${MAX_RAW_BLOCKS} 条`);
    
    // ✅ 性能监控
    const startTime = Date.now();
    
    // 1. 从 Redis 加载动态计算的数据量
    const allBlocks = await getBlocks(MAX_RAW_BLOCKS);
    const loadTime = Date.now();
    
    // 2. 在内存中快速过滤
    let filteredBlocks = allBlocks;
    if (ruleValue > 1) {
      filteredBlocks = allBlocks.filter(block => {
        if (startBlock > 0) {
          return block.height >= startBlock && (block.height - startBlock) % ruleValue === 0;
        }
        return block.height % ruleValue === 0;
      });
    }
    const filterTime = Date.now();
    
    // 3. 返回前 264 条
    const resultBlocks = filteredBlocks.slice(0, limit);
    const endTime = Date.now();
    
    console.log(`[API] ⏱️ 性能统计:`);
    console.log(`  - Redis 加载: ${loadTime - startTime}ms`);
    console.log(`  - 内存过滤: ${filterTime - loadTime}ms`);
    console.log(`  - 总耗时: ${endTime - startTime}ms`);
    
    res.json({
      success: true,
      data: resultBlocks,
      count: resultBlocks.length,
      metadata: {
        ruleValue,
        startBlock,
        totalRaw: allBlocks.length,
        totalFiltered: filteredBlocks.length,
        returned: resultBlocks.length,
        estimatedRawBlocks,
        actualRawBlocks: MAX_RAW_BLOCKS,
        performance: {
          redisLoad: loadTime - startTime,
          memoryFilter: filterTime - loadTime,
          total: endTime - startTime,
        }
      }
    });
  } catch (error: any) {
    console.error('[API] ❌ 错误:', error.message);
    res.status(500).json({
      success: false,
      error: error.message,
    });
  }
});
```

---

### 方案3：优化依赖项（问题4）

#### 核心设计

使用 `useRef` 存储 `blocksCache`，避免将其作为依赖项。

#### 实现代码

```typescript
// 1. 添加 ref
const blocksCacheRef = useRef(new Map<string, BlockData[]>());

// 2. 同步更新 ref
useEffect(() => {
  blocksCacheRef.current = blocksCache;
}, [blocksCache]);

// 3. 在 loadHistoryBlocks 中使用 ref
const loadHistoryBlocks = useCallback(async (forceReload: boolean = false) => {
  const cacheKey = `${ruleValue}-${startBlock}`;
  
  // ✅ 使用 ref 而不是直接访问 blocksCache
  if (!forceReload && blocksCacheRef.current.has(cacheKey)) {
    const cachedData = blocksCacheRef.current.get(cacheKey)!;
    // ...
  }
  
  // ...
}, [activeRule]);  // ✅ 不包含 blocksCache 依赖
```

---

## 📊 综合性能分析

### 场景1：首次切换到规则（缓存未命中）

#### 步长1（3秒规则）

**修复前**：
```
Redis 加载 30,000 条  →  ~300ms
内存过滤 30,000 条    →  ~100ms
返回 264 条          →  ~10ms
─────────────────────────────
总耗时：~410ms
```

**修复后（方案2：后端动态加载）**：
```
Redis 加载 396 条     →  ~20ms
内存过滤 396 条       →  ~5ms
返回 264 条          →  ~10ms
─────────────────────────────
总耗时：~35ms
性能提升：11.7 倍 ⬆️
```

#### 步长20（1分钟规则）

**修复前**：
```
Redis 加载 30,000 条  →  ~300ms
内存过滤 30,000 条    →  ~100ms
返回 264 条          →  ~10ms
─────────────────────────────
总耗时：~410ms
```

**修复后（方案2：后端动态加载）**：
```
Redis 加载 7,920 条   →  ~80ms
内存过滤 7,920 条     →  ~20ms
返回 264 条          →  ~10ms
─────────────────────────────
总耗时：~110ms
性能提升：3.7 倍 ⬆️
```

---

### 场景2：切换回已访问规则（缓存命中）

**修复前**：
```
Redis 加载 30,000 条  →  ~300ms
内存过滤 30,000 条    →  ~100ms
返回 264 条          →  ~10ms
─────────────────────────────
总耗时：~410ms
```

**修复后（方案1：前端缓存）**：
```
检查缓存             →  ~1ms
使用缓存数据          →  ~5ms
显示数据             →  ~4ms
─────────────────────────────
总耗时：~10ms
性能提升：41 倍 ⬆️
```

---

### 场景3：频繁切换2个规则

**用户操作**：规则A → 规则B → 规则A → 规则B → 规则A

**修复前**：
```
切换到规则A（首次）  →  ~410ms
切换到规则B（首次）  →  ~410ms
切换回规则A         →  ~410ms  ❌ 重新加载
切换回规则B         →  ~410ms  ❌ 重新加载
切换回规则A         →  ~410ms  ❌ 重新加载
─────────────────────────────
总耗时：~2,050ms
```

**修复后（方案1 + 方案2）**：
```
切换到规则A（首次）  →  ~35ms   ✅ 后端动态加载
切换到规则B（首次）  →  ~35ms   ✅ 后端动态加载
切换回规则A         →  ~10ms   ✅ 缓存命中
切换回规则B         →  ~10ms   ✅ 缓存命中
切换回规则A         →  ~10ms   ✅ 缓存命中
─────────────────────────────
总耗时：~100ms
性能提升：20.5 倍 ⬆️
```

---

## 🎯 前端缓存 + 后端动态加载的协同效果

### 核心优势

**1. 缓存命中时，完全不需要后端请求**

```
用户切换到已访问规则
  ↓
检查前端缓存
  ↓
缓存命中！
  ↓
直接使用缓存数据（~10ms）
  ↓
✅ 不进行网络请求
✅ 不消耗后端资源
✅ 用户体验极佳
```

**2. 缓存未命中时，后端动态加载减少数据量**

```
用户切换到新规则
  ↓
检查前端缓存
  ↓
缓存未命中
  ↓
后端动态计算需要加载的数据量
  ↓
只加载必要的数据（例如：396条而不是30,000条）
  ↓
快速返回（~35ms而不是~410ms）
  ↓
✅ 减少网络传输
✅ 减少内存占用
✅ 减少CPU消耗
```

### 性能对比表

| 场景 | 修复前 | 只有前端缓存 | 只有后端优化 | 前端缓存+后端优化 | 最终提升 |
|------|--------|-------------|-------------|------------------|---------|
| 首次切换（步长1） | 410ms | 410ms | 35ms | 35ms | 11.7倍 ⬆️ |
| 首次切换（步长20） | 410ms | 410ms | 110ms | 110ms | 3.7倍 ⬆️ |
| 切换回已访问规则 | 410ms | 10ms | 410ms | 10ms | 41倍 ⬆️ |
| 频繁切换2个规则 | 2,050ms | 460ms | 290ms | 100ms | 20.5倍 ⬆️ |

### 缓存命中率分析

**理想情况（用户主要使用3个规则）**：
```
第1次切换：缓存未命中，后端加载（~35ms）
第2次切换：缓存未命中，后端加载（~35ms）
第3次切换：缓存未命中，后端加载（~35ms）
第4次切换：缓存命中！（~10ms）
第5次切换：缓存命中！（~10ms）
第6次切换：缓存命中！（~10ms）
...

缓存命中率：随着使用时间增加，逐渐接近100%
平均耗时：从~410ms降低到~10ms
```

---

## 🚀 实施步骤

### 阶段1：实施前端缓存（优先级：高）

**预期效果**：缓存命中时，性能提升41倍

**步骤**：
1. 添加 `blocksCache` 状态
2. 修改 `loadHistoryBlocks` 函数，添加缓存检查
3. 修改规则切换逻辑，移除强制重新加载
4. 修改 WebSocket 数据更新，同步缓存
5. 测试缓存功能

**耗时**：约2小时

---

### 阶段2：实施后端动态加载（优先级：高）

**预期效果**：首次加载时，性能提升3-12倍

**步骤**：
1. 修改 `/api/blocks` 端点，添加动态计算逻辑
2. 测试不同步长的加载性能
3. 调整安全系数（如果需要）
4. 监控生产环境性能

**耗时**：约1小时

---

### 阶段3：优化依赖项（优先级：中）

**预期效果**：减少不必要的函数重新创建

**步骤**：
1. 添加 `blocksCacheRef`
2. 同步更新 ref
3. 修改 `loadHistoryBlocks` 依赖项
4. 测试功能

**耗时**：约30分钟

---

## 📈 监控指标

### 前端监控

```typescript
// 1. 缓存命中率
let cacheHits = 0;
let cacheMisses = 0;

if (blocksCache.has(cacheKey)) {
  cacheHits++;
  console.log(`[缓存] 📊 命中率: ${(cacheHits / (cacheHits + cacheMisses) * 100).toFixed(1)}%`);
} else {
  cacheMisses++;
}

// 2. 缓存大小
console.log(`[缓存] 📊 缓存统计: ${blocksCache.size} 个规则`);

// 3. 内存占用
const estimatedMemory = blocksCache.size * 132;  // KB
console.log(`[缓存] 💾 估算内存占用: ${estimatedMemory.toFixed(0)} KB`);
```

### 后端监控

```typescript
// 1. 数据加载量
console.log(`[API] 📊 预估加载: ${estimatedRawBlocks} 条，实际加载: ${MAX_RAW_BLOCKS} 条`);

// 2. 性能统计
console.log(`[API] ⏱️ 性能统计:`);
console.log(`  - Redis 加载: ${loadTime - startTime}ms`);
console.log(`  - 内存过滤: ${filterTime - loadTime}ms`);
console.log(`  - 总耗时: ${endTime - startTime}ms`);

// 3. 优化效果
const dataReduction = ((1 - MAX_RAW_BLOCKS / 30000) * 100).toFixed(1);
console.log(`[API] 💾 数据加载优化: 减少 ${dataReduction}% 的数据加载`);
```

---

## 📝 总结

### 问题根源
1. 每次切换规则都强制重新加载数据
2. 后端每次都加载30,000条原始数据
3. 前端没有缓存机制
4. loadHistoryBlocks依赖项过多

### 综合解决方案
1. **前端缓存**：缓存每个规则的264条符合规则的最新数据
2. **后端动态加载**：根据步长动态计算需要加载的数据量
3. **优化依赖项**：使用useRef避免不必要的函数重新创建

### 预期效果
- **缓存命中时**：41倍性能提升（410ms → 10ms）
- **首次加载（步长1）**：11.7倍性能提升（410ms → 35ms）
- **首次加载（步长20）**：3.7倍性能提升（410ms → 110ms）
- **频繁切换2个规则**：20.5倍性能提升（2,050ms → 100ms）

### 核心优势
- ✅ **前端缓存**：缓存命中时，完全不需要后端请求
- ✅ **后端优化**：缓存未命中时，减少数据加载量
- ✅ **协同效果**：两者结合，性能提升最大化
- ✅ **用户体验**：切换规则几乎无延迟

---

**文档创建时间**：2026-02-07  
**文档版本**：1.0
